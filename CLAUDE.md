# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

SmallAI converts natural language log queries into Splunk SPL (Search Processing Language) using a hybrid ML + rule-based approach. The system uses TF-IDF + Logistic Regression classifiers for slot filling (action, time, user, source) with rule-based regex fallbacks for robustness.

## Core Architecture

### Three Parser Implementations

1. **rule_based_parser.py** - Regex and keyword dictionary baseline
   - Function: `parse_query(nl_query)` returns slot dict
   - Uses keyword maps: `action_keywords`, `time_keywords`, `source_keywords`, `users`
   - Returns structured format: `{"action": "...", "time": "...", "user": "...", "source": "..."}`

2. **ml_parser.py** - Pure ML approach
   - Trains 4 separate TF-IDF + LogisticRegression classifiers (one per slot)
   - Function: `train_all()` returns tuple of 4 trained Pipeline objects
   - Function: `predict_query(q, clf_a, clf_t, clf_u, clf_s)` returns slot dict
   - Dataset path: `datasets/log_query_dataset.csv`

3. **hybrid_parser.py** - Production implementation (main CLI)
   - Combines ML predictions with rule-based fallbacks
   - Uses confidence threshold (`CONF_THRESHOLD=0.7` by default)
   - Falls back to rule-based parsing when ML confidence is low
   - Includes interactive clarification prompts (skippable with `-f` force flag)
   - Function: `to_spl(slots)` generates final Splunk query

### Data Flow

```
Natural Language Query
  → ML Prediction (per-slot with confidence scores)
  → Rule-based Fallback (if confidence < threshold)
  → Normalization (wildcards for missing values)
  → Optional CLI Clarification (interactive mode only)
  → SPL Generation (to_spl function)
```

## Critical Invariants

⚠️ **DO NOT BREAK THESE:**

1. **Slot names are fixed:** `action`, `time`, `user`, `source`, `src_ip`, `hostname`, `severity`, `status_code` - used consistently across all parsers
2. **Wildcard convention:** Unknown/unspecified slots use `"*"` (string literal), never `None`
3. **Structured string format:** `action=X time=Y user=Z source=W src_ip=A hostname=B severity=C status_code=D` (see `structured_string()` in rule_based_parser.py)
4. **Dataset columns:** `nl_query,action,time,user,source,src_ip,hostname,severity,status_code,structured_query,event_ts` - changing these breaks evaluation scripts

## Common Development Commands

### Installation
```bash
pip install -r requirements.txt
```

### Running Parsers

**First time setup - Train and save models:**
```bash
python hybrid_parser.py --train
```

This trains ML models and saves them to `models/` directory. Models are persisted using joblib and loaded automatically on subsequent runs.

Interactive mode (with clarification prompts):
```bash
python hybrid_parser.py "show me failed logins from yesterday"
# or
./hybrid_parser.py "show me failed logins from yesterday"
```

Force mode (no prompts, auto-fill with wildcards):
```bash
python hybrid_parser.py -f "show me failed logins from yesterday"
```

**Note:** If models aren't trained yet, the parser will show a warning and fall back to rule-based parsing only.

Rule-based only:
```bash
python rule_based_parser.py "query text here"
# or run evaluation:
python rule_based_parser.py
```

ML-only:
```bash
python ml_parser.py "query text here"
```

### Evaluation & Testing

Run full Phase 2 validation (includes train/test split):
```bash
python scripts/phase2_validation.py
```

This generates `docs/accuracy_report.md` with performance metrics.

Run accuracy evaluation across all parsers:
```bash
python eval_accuracy.py
```

### API Server

Start FastAPI server:
```bash
python deploy/serve.py
# or
uvicorn deploy.serve:app --reload
```

Query endpoint:
```bash
curl -X POST http://localhost:8000/rewrite-query \
  -H "Content-Type: application/json" \
  -d '{"query": "show failed logins from yesterday"}'
```

### Dataset Generation

Regenerate synthetic dataset:
```bash
python datasets/generate_dataset.py
```

## Key File Locations

- **Main parsers:** `hybrid_parser.py`, `ml_parser.py`, `rule_based_parser.py` (all in root)
- **Dataset:** `datasets/log_query_dataset.csv`
- **Trained models:** `models/*.joblib` (gitignored, generated by `--train`)
- **API deployment:** `deploy/serve.py`
- **Validation script:** `scripts/phase2_validation.py`
- **Accuracy report:** `docs/accuracy_report.md` (auto-generated)
- **Drift monitoring:** `drift_hook.py` and `logs/unparsed_queries.log`

## Making Common Changes

### Add New Action Type
1. Update `action_keywords` dict in `rule_based_parser.py`
2. Update `action_templates` dict in `hybrid_parser.py` (SPL search terms)
3. Add training examples to `datasets/log_query_dataset.csv`
4. Re-run `python scripts/phase2_validation.py` to verify

### Add New Source Type
1. Update `source_keywords` in `rule_based_parser.py`
2. Update `source_to_sourcetype` mapping in `hybrid_parser.py`
3. Add to `known_sourcetypes` list in `hybrid_parser.py`
4. Add training examples to dataset

### Modify Time Range Mapping
Update `time_map` dict in `hybrid_parser.py`:
```python
time_map = {
    "last1h": "-1h",
    "last24h": "-24h",
    # add new mappings here
}
```

### Change Confidence Threshold
Modify `CONF_THRESHOLD` constant in `hybrid_parser.py` (default: 0.7)

### Change Default Splunk Index
Modify the `index` parameter in `to_spl()` function in `hybrid_parser.py` (currently hardcoded to "main")

## Important Patterns

### Slot Dictionary Structure (8 slots for NOC queries)
```python
{
    "action": "failure",      # or "login", "error", "upload", "access", etc.
    "time": "last24h",        # or "today", "last1h", "last30d", etc.
    "user": "*",              # username or "*" for wildcard
    "source": "auth",         # or "web", "ssh", "database", "filesystem", "host", "*"
    "src_ip": "10.0.0.1",     # source IP address or "*"
    "hostname": "web-server-01", # server/device name or "*"
    "severity": "critical",   # critical, error, warning, info, or "*"
    "status_code": "404"      # HTTP status code (200, 404, 500, etc.) or "*"
}
```

### SPL Output Pattern
```spl
index=main sourcetype=syslog ("Failed password" OR "auth failure") earliest=-24h@h latest=now
```

## Known Quirks

1. **Model persistence:** ML models are saved to `models/` directory using joblib. Run `python hybrid_parser.py --train` to train and save models. Models are loaded automatically on subsequent runs.

2. **Dataset path inconsistency:** Some files expect dataset at root (`log_query_dataset.csv`), others at `datasets/log_query_dataset.csv`. The current production path is `datasets/log_query_dataset.csv`.

3. **Import paths:** Most parsers are in root directory, so imports are simple. `eval_accuracy.py` adds `src/` to path but parsers aren't actually in `src/`.

4. **Force mode flag:** The `-f` flag must appear BEFORE the query text: `python hybrid_parser.py -f "query"`

## Testing & Validation

- **Current architecture:** 8-slot system designed for NOC (Network Operations Center) use cases
- **Model count:** 8 ML classifiers (one per slot: action, time, user, source, src_ip, hostname, severity, status_code)
- **Total model size:** ~500KB (8 joblib files)

- **Drift monitoring:** Unparsed or low-confidence queries are logged to `logs/unparsed_queries.log` via `drift_hook.py`

## Dependencies

Core libraries (from `requirements.txt`):
- scikit-learn >= 1.3 (ML models)
- numpy >= 1.25
- pandas >= 2.1
- uvicorn >= 0.22 (API server)
- pydantic >= 1.10 (API models)
- pyyaml >= 6.0

Python version: 3.9+ (per README)

## Code Style Notes

From `.github/copilot-instructions.md`:
- Small PRs preferred (< 200 lines)
- All functional changes require tests
- Commit format: `type(scope): description`
- No secrets, credentials, or real log data in commits
- Preserve slot key names and wildcard semantics when refactoring
